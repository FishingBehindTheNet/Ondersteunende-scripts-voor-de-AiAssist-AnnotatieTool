{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Ondersteunende scripts voor de AiAssist-AnnotatieTool**\n",
    "Deze repo is gemaakt ter ondersteuning van de [AiAssist-AnnotatieTool van FishingBehindTheNet](https://github.com/FishingBehindTheNet/AiAssist-AnnotatieTool), een pijplijn voor het annoteren en het maken van modellen voor gebruik bij AI-assisted annoteren. De ondersteunende scripts gebruiken dezelfde bibliotheken de AiAssist-Anotatietool en zijn daarom gebouwd op Python 3.9 en maken gebruik van alle bibliotheken in BASIS_requirements.txt en CPU_requirements.txt. Wanneer de computer een Nvidia GPU heeft met [CUDA-ondersteuning](https://developer.nvidia.com/cuda-gpus), wordt aanbevolen om GPU_requirements.txt te gebruiken in plaats van CPU_requirements.txt voor een versnelde trainings- en validatietijd.\n",
    "\n",
    "Hieronder worden de scripts kort geïntroduceerd en kun je doorklikken naar de daadwerkelijke code. Ook is er een Unsupported folder. Hier vind je scripts die gedurende de loop van verschillende projecten rondom de tool zijn gemaakt en gebruikt. De scripts kunnen hergebruikt worden, maar hebben mogelijk updates nodig om met nieuwe data te werken. Unsupported betekent hierbij dat de eventuele updates van de scripts de verantwoordelijkheid van de gebruiker zijn. Eventuele aanpassingen die gedaan worden, kunnen wel gedeeld worden op de [GitHub-pagina](https://github.com/FishingBehindTheNet/Ondersteunende-scripts-voor-de-AiAssist-AnnotatieTool), waarna ze mogelijk als update worden opgenomen in de hoofdrepository. Dit zorgt ervoor dat iedereen kan profiteren van verbeteringen en aanpassingen die door andere gebruikers worden bijgedragen.\n",
    "\n",
    "Voor hulp bij het installeren of gebruik van de AiAssist-AnnotatieTool en ondersteunende scripts kun je gebruikmaken van [de gebruikershandleiding op YouTube](https://youtube.com/playlist?list=PLwGilaj42u_BGJXtdqZDr2L8PZZgEVBhq&si=1MtIZU8fEtOM6cHQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Bestanden Hernoemen](./BestandenHernoemen/BestandenHernoemen.ipynb)\n",
    "Dit script vereenvoudigt het hernoemen van bestanden op basis van projectvariabelen. Het script gebruikt de mapstructuur en gebruikersinput om alle bestanden in een map te hernoemen. Dit zorgt voor duidelijkheid tijdens het annoteren en beoordelen van resultaten, en is noodzakelijk voor het gebruik van meerdere scripts binnen deze repository. Het is het gemakkelijkst om je bestanden te hernoemen voordat je foto's segmenteert of annoteert.\n",
    "\n",
    "Het script werkt op basis van het opgegeven pad. Wanneer de inputlocatie \"c:\\gebruiker\\python\\script\\ProjectNaam\" is, worden alle bestanden in \"ProjectNaam\" en de onderliggende mappen meegenomen. Dit betekent dat met MapSelectie = [0, -2] een bestand gevonden op locatie:\n",
    "\"c:\\gebruiker\\python\\script\\\\<b>ProjectNaam\\variabel1\\variabel2\\variabel3\\Bestand1.png</b>\" \n",
    "\n",
    "hernoemd zal worden als \"Bestand1-variabel1-variabel2.png\" terwijl een ander bestand gevonden op: \"c:\\gebruiker\\python\\script\\\\<b>ProjectNaam\\variabel1\\variabel2\\variabel3\\variabel4\\Bestand2.png</b>\" \n",
    "\n",
    "hernoemd zal worden als \"Bestand2-variabel1-variabel3.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [HeleKaart Predictie](./HeleKaartPredictie/HeleKaartPredictie.ipynb)\n",
    "Deze script is bedoeld om voorspellingen te doen op volledige foto's die normaal gesproken gesegmenteerd worden voordat het model ze ziet. Foto's worden gesegmenteerd, geannoteerd door het model, en de labels worden samengevoegd tot één groot label per foto. De gebruiker wordt gevraagd om de verwachte grootte, oriëntatie en lengte van de originele foto's op te geven om onverwachte en soms onzichtbare rotaties in foto's te neutraliseren.\n",
    "\n",
    "Na het genereren van labels is het van belang dat de output gecontroleerd wordt, met een nadruk op de naden/randen van de segmenten. Als bij het genereren een overlap groter dan 0 is opgegeven, is de kans op overlappende annotaties vergroot en zal hierop gecontroleerd moeten worden.\n",
    "De gegenereerde segmenten en bijbehorende labels staan in de map \"Tijdelijke data\". Mocht een gebruiker interesse hebben in deze data, dan moet deze alle bestanden kopiëren naar een nieuwe locatie voordat het script opnieuw gedraaid wordt.\n",
    "\n",
    "**LET OP!** Bij het draaien van het script worden naast de tijdelijke bestanden ook de opgegeven OutputLocatie opgeruimd, waarbij alle bestanden in deze mappen verwijderd worden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Herhaaldelijke Validatie](./HerhaaldelijkeValidatie/HerhaaldelijkeValidatie.ipynb)\n",
    "Dit script is bedoeld om een model te valideren op een volledige dataset. Het script maakt datasets/datapunten op basis van segmentatie, maar wanneer afbeeldingen niet gesegmenteerd zijn of te weinig segmenten en/of bounding boxes bevatten, kan de optie \"GebruikVariabelClustering\" op True worden gezet. Dit zorgt ervoor dat de datasets worden aangemaakt op basis van de unieke combinatie van variabelen in plaats van segmenten. In dit geval zou \"0002_A52_flits_1\" bijvoorbeeld in de dataset \"A52_Flits_1\" komen, in plaats van in \"0002_A52_flits_1\".\n",
    "Na het maken van de datasets/datapunten wordt het opgegeven model op deze datasets/datapunten gevalideerd. Dit biedt de gebruiker de mogelijkheid om de effecten van verschillende variabelen te analyseren. De output van het script is een Excel-bestand met gedetailleerde informatie over de prestaties van iedere dataset/datapunt, zoals precisie, F1-score, confusion matrix, enzovoort. Daarnaast is het mogelijk om clusters van verschillende variabelen te maken door de positie van het cluster op te geven via de variabele \"Clustering\" om de effecten van combinaties van verschillende variabelen te analyseren. Dit betekent dat alle afbeeldingen, naast dat ze in de individuele datasets terechtkomen, ook toegevoegd worden aan de dataset die de opgegeven combinatie van variabelen weerspiegelt. Bijvoorbeeld, een afbeelding met de naam \"0002_A52_flits_1_0_0\" en een clustering van [2,3] komt niet alleen in de dataset \"0002_A52_flits_1\" terecht, maar ook in de dataset \"Cluster van A52 en flits\". Een andere afbeelding, zoals \"0002_ip7_flits_1_0_0\", komt in de dataset \"0002_ip7_flits_1\" en \"Cluster van ip7 en flits\" terecht. \n",
    "\n",
    "**LET OP!** Dit script gaat er vanuit dat de bestanden cordinaten (\"0002_ip7_flits_1**_0_0**\") en/of variabelen (\"0002**_ip7_flits_1**_0_0\") in de naam hebben. Voor het gemakelijk toeveoegen van variabelen in de naam zie [BestandenHernoemen.ipynb](./BestandenHernoemen/BestandenHernoemen.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Image resize](./Image%20resize/ImageResize.ipynb)\n",
    "Dit script is bedoeld om foto's te upscale, downscale en draaien. Deze functionaliteit is bij veel van de scripts in deze repository al ingebouwd. Alleen hier vind je de functionaliteit vrijstaand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Label Assembly](./LabelAssembly/LabelAssembly.ipynb)\n",
    "Dit script is bedoeld om gelabelde segmenten samen te plakken tot de originele afbeelding met een bijbehorend label. Het script kan verschillende afbeeldingen en afbeelding formaten verwerken en berekend de correcte afmetingen per afbeelding. Wanneer er verschillende Label.txt bestanden gevonden worden met unieke inhoud word er van iedere unieke inhoud een versie opgeslagen met een oplopend nummer in de naam. Een Label word pas mee genomen in de output als er zowel een label als een bijbehorend segment aangeleverd word. Voor de segmenten zelf kan deze overweging door de gebruiker ingesteld worden. \n",
    "\n",
    "**LET OP!** Bij het draaien van het script wordt de opgegeven OutputLocatie opgeruimd, waarbij alle bestanden in deze map verwijderd wordt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Make Confusion Matrix](./MakeConfusionMatrix/MakeConfusionMatrix.ipynb)\n",
    "Dit script is bedoelt om Confusion matrixen te maken van validatie data uit het script \"HerhaaldelijkeValidatie.ipynb\". Het script bied de mogelijkheid om geclusterde matrixen te maken van clusters die niet bij de \"HerhaaldelijkeValidatie.ipynb\" zijn gebruikt. Daarnaast is het mogelijk om namen van labels en variabel te corrigeren waar nodig.\n",
    "\n",
    "**LET OP!** Wanneer de opgeslagen matrixen toegevoegd worden aan een Microsoft word document (en mogelijk anderen bestandstype) kan de kwaliteit van de afbeelding negatief beïnvloed worden om dit tegen te gaan kun je [deze instelling](https://support.microsoft.com/en-us/office/change-the-default-resolution-for-inserting-pictures-in-office-f4aca5b4-6332-48c6-9488-bf5e0094a7d2) of [deze instelling](https://support.microsoft.com/en-us/office/turn-off-picture-compression-81a6b603-0266-4451-b08e-fc1bf58da658) aanpassen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Unsupported:** [Data extractie Imec](./Unsupported/Dataextracie%20Imec/ImecExtractie.ipynb)\n",
    "Dit script is geschreven om de resultaten van het beeldherkenningsmodel van IMEC te verzamelen. Tijdens verschillende projecten is, naast het trainen van een model met Custom Vision of YOLOv8, ook een model getraind en ontwikkeld door onderzoekers van IMEC. Om de prestaties van dit model te testen, heeft IMEC validaties uitgevoerd en de resultaten in de vorm van een JSON-bestand opgestuurd. Dit script heeft als doel deze resultaten uit te lezen en op te slaan in een bewerkbaar Excel-formaat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Unsupported:** [Labelbox To Yolo](./Unsupported/Labelbox%20data%20extract/LabelboxToYolo.ipynb)\n",
    "Dit script is geschreven tijdens de overgang van custom vision modellen naar yolo modellen. Het annoteren van afbeeldingen wert gedaan met behulp van [Labelbox](https://labelbox.com/) een gratis online annotatie programma waar je met meerdere mensen samen kan annoteren. De annotaties van Labelbox konden gedownload worden als een json file met daarin labels voor alle foto's van een project in coco notatie. Dit script is bedoeld om dit Json bestand te converteren naar verschillende txt bestanden met ieder de labels van één afbeelding in YOLO notatie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Unsupported:** [Labelbox DataMine](./Unsupported/Labelbox%20data%20extract/LabelboxDataMine.ipynb)\n",
    "Dit script is geschreven om annotaties van modellen handmatig te kunnen controleren. Wanneer een project data van een model kreeg met de labels in de afbeelding \"geprint\" of allen de labels en niet of deze klopte met de werkelijkheid moest iedere annotatie van het model handmatig gecontroleerd worden. Hiervoor werd [Labelbox](https://labelbox.com/) gebruikt. Labelbox bied de mogelijkheid label voorschriften te maken waarbij naast het label ook een sub-label geselecteerd moet worden voor een valide annotatie. Dit betekend dat je de annotaties en/of labels in Labelbox kan laden en voor iedere bounding box en/of object een nieuwe annotatie kan maken waarbij je eerst annoteert welk label iets moet krijgen en het sub-label gebruikte om aan te geven wat het model er van maakt. Net als bij [**Unsupported:** Labelbox To Yolo](./Unsupported/Labelbox%20data%20extract/LabelboxToYolo.ipynb) kun je dan de annotaties downloaden in de vorm van een Json file. Dit script is bedoelt om de annotaties uit de json lezen en op te slaan in een ExcelFile voor verdere resultaat verwerking. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
