{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importeer benodigde modules\n",
    "from IPython.display import display\n",
    "from pathlib import Path, PurePath\n",
    "from tqdm.notebook import tqdm\n",
    "from ultralytics import YOLO\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import shutil\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Herhaaldelijke Validatie\n",
    "Dit script is bedoeld om een model te valideren op een volledige dataset. Het script maakt datasets/datapunten op basis van segmentatie, maar wanneer afbeeldingen niet gesegmenteerd zijn of te weinig segmenten en/of bounding boxes bevatten, kan de optie \"GebruikVariabelClustering\" op True worden gezet. Dit zorgt ervoor dat de datasets worden aangemaakt op basis van de unieke combinatie van variabelen in plaats van segmenten. In dit geval zou \"0002_A52_flits_1\" bijvoorbeeld in de dataset \"A52_Flits_1\" komen, in plaats van in \"0002_A52_flits_1\".\n",
    "Na het maken van de datasets/datapunten wordt het opgegeven model op deze datasets/datapunten gevalideerd. Dit biedt de gebruiker de mogelijkheid om de effecten van verschillende variabelen te analyseren. De output van het script is een Excel-bestand met gedetailleerde informatie over de prestaties van iedere dataset/datapunt, zoals precisie, F1-score, confusion matrix, enzovoort. Daarnaast is het mogelijk om clusters van verschillende variabelen te maken door de positie van het cluster op te geven via de variabele \"Clustering\" om de effecten van combinaties van verschillende variabelen te analyseren. Dit betekent dat alle afbeeldingen, naast dat ze in de individuele datasets terechtkomen, ook toegevoegd worden aan de dataset die de opgegeven combinatie van variabelen weerspiegelt. Bijvoorbeeld, een afbeelding met de naam \"0002_A52_flits_1_0_0\" en een clustering van [2,3] komt niet alleen in de dataset \"0002_A52_flits_1\" terecht, maar ook in de dataset \"Cluster van A52 en flits\". Een andere afbeelding, zoals \"0002_ip7_flits_1_0_0\", komt in de dataset \"0002_ip7_flits_1\" en \"Cluster van ip7 en flits\" terecht. \n",
    "\n",
    "**LET OP!** Dit script gaat er vanuit dat de bestanden cordinaten (\"0002_ip7_flits_1 **_0_0** \") en/of variabelen (\"0002 **_ip7_flits_1** _0_0\") in de naam hebben. Voor het gemakelijk toeveoegen van variabelen in de naam zie \"BestandenHernoemen.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<blockquote style=\"border-left: 5px solid red; padding-left: 10px;\">\n",
    "\n",
    "## **Attentie!** \n",
    "<code> Update onderstaande cell voordat je de het script runt </code></blockquote>\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input map met de segmenten en labels.\n",
    "InputAnnotaties : list[Path] = [Path(r\"pad/naar/jouw/folder\"), Path(r\"pad/naar/jouw/andere/folder\")] #segmenten en labels allenbij\n",
    "# Bijvoorbeeld: [Path(r\"pad/naar/jouw/folder\"), Path(r\"pad/naar/jouw/andere/folder\")]\n",
    "\n",
    "# Output map waar de \"Stitched Images en labels\" worden opgeslagen.\n",
    "OutputFolder : Path = Path(r\"Nieuwe Map\")\n",
    "# Bijvoorbeeld: Path(r\"pad/naar/jouw/output/folder\") OF Path(r\"Nieuwe Map\")\n",
    "\n",
    "# Locatie van het model dat gebruikt wordt (Moet .onnx of .pt zijn).\n",
    "ModelLocatie : Path = Path(r\"pad/naar/jouw/model/bestand.pt\")\n",
    "# Bijvoorbeeld: Path(r\"pad/naar/jouw/model/bestand.pt\")\n",
    "\n",
    "# Validaties met te weinig annotaties/ afbeeldingen zijn onbetrouwbaar. Om dit tegen te gaan bepaal of:\n",
    "    # FALSE : één datapunt bestaat uit alle segmenten van een afbeelding (\"0002_A52_flits_1_0_0\" staat in datapunt: \"0002_A52_flits\")\n",
    "    # TRUE : één datapunt bestaat uit alle afbeeldingen met die unieke combinatie van variabelen. (\"0002_A52_flits_1_0_0\" staat in datapunt: \"A52_flits\")\n",
    "GebruikVariabelClustering : bool = True\n",
    "# Bijvoorbeeld: True OF False\n",
    "\n",
    "# Welk scheidingsteken word gebruikt in de naam tussen de variabelen? Bijv. \"0002_A52_flits_1_0_0\" ScheidingsTeken = \"_\"\n",
    "    # Wanneer de variabele leeg blijft worden er geen extra kolommen gemaakt voor de variabelen\n",
    "ScheidingsTekenVariabelen : str = \"-\"\n",
    "# Bijvoorbeeld: \"-\" of \"_\" of \"\" etc.\n",
    "\n",
    "# Welke variabele wil je combineren voor een extra variabelen. Bijv. \"0002_A52_flits_1_0_0\" variabele 2= A52 (Rest van dataset: ip7 of ip13), variabele 3= flits (Rest van dataset: Geen flits)\n",
    "    # dus met Clustering = [2, 3] is er een tabblad voor alle mogelijke combinaties van variabele [A52, ip7, ip13] met [Flits, Geen flits] in de output aanwezig\n",
    "Clustering : list[int] = []\n",
    "# Bijvoorbeeld: [0, 2] OF []\n",
    "\n",
    "# Voor variabelen met verschillende namen maar die wel als een geclusterd moeten worden. Bijv. \"0002_A52_flits_1_0_0\" variabele 2= A52 (Rest van dataset: ip7 of ip13)\n",
    "    # VariabelenMatch = {\"Ip\" : [\"ip7\", \"ip13\"]} zocht er voor dat wanneer een variabele ip7 of ip13 is deze in de clustering als \"Ip\" herkent worden maar in de losse foto's nog wel correct genoteerd staan\n",
    "    # In de clusters komt dus allen A52 en Ip terug voor variabele 2\n",
    "VariabelenMatch : dict[str, list[int]] = {} # HOOFDLETTER GEVOELIG!\n",
    "# Bijvoorbeeld: {\"Ip\" : [\"ip7\", \"ip13\"], \"Clusternaam\": [\"OGVariabel1\", \"OGVariabel2\", \"OGVariabel5\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **Code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Onderdrukt de printstatements van yolo\n",
    "logging.getLogger('ultralytics').setLevel(logging.ERROR)\n",
    "\n",
    "# Standaardiseer benaming van clusters. aanpassingen hier worden in het hele script gebruikt\n",
    "ClusterSignaal = \"Cluster van \"\n",
    "EnSignaal = \" en \"\n",
    "labels = \"\"\n",
    "ScheidingsTekenCoördinaten = \"_\"\n",
    "MinimaalAantalBBoxen = 10\n",
    "MinimaalAantalBestanden = 5\n",
    "\n",
    "# aanmaak lege variabelen\n",
    "PathsInput = []\n",
    "DuplicaatDocumenten = []\n",
    "AllTextInput = []\n",
    "AllImageInput = []\n",
    "RootFiles = set()\n",
    "ClusterDictionary ={}\n",
    "\n",
    "# Voorkomt verwarring door oude data\n",
    "if os.path.exists(OutputFolder):\n",
    "    shutil.rmtree(OutputFolder)\n",
    "\n",
    "# Maak de display widgets aan\n",
    "OutputScreen = widgets.Output()\n",
    "OutputScreenLoadingBar = widgets.Output()\n",
    "OutputScreenPrintDisplay = widgets.Output()\n",
    "with OutputScreen:\n",
    "    display(OutputScreenLoadingBar)\n",
    "    display(OutputScreenPrintDisplay)\n",
    "\n",
    "# Standaardiseert en centreert het kopiëren en opslaan van bestanden naar de correcte locatie (YOLO Map structuur)\n",
    "def FileCopy(OutputFolder = OutputFolder, Main : str = None, IsLabel : bool = None, FilePath : Path = None):\n",
    "    OutputDir = os.path.join(OutputFolder, Main, (\"labels\" if IsLabel else \"images\"), \"validation\")\n",
    "    if not os.path.exists(OutputDir):\n",
    "        os.makedirs(OutputDir)\n",
    "    if not os.path.exists(os.path.join(OutputDir, FilePath.name)):\n",
    "        shutil.copy2(FilePath, OutputDir)\n",
    "    else:\n",
    "        # Maakt een lijst met duplicaat bestanden die later geprint worden. Zo kan de Gebruiker controleren of het skippen terecht was\n",
    "        DuplicaatDocumenten.append(FilePath)\n",
    "\n",
    "# Safety checks van de opgegeven data zodat errors beter te vertalen zijn\n",
    "for dir in InputAnnotaties:\n",
    "    if not os.path.exists(dir):\n",
    "        sys.exit(\"Een of meerdere van de opgegeven mappen in FilePaths kan niet gevonden worden. de code is onderbroken\")\n",
    "if not os.path.exists(ModelLocatie):\n",
    "    sys.exit(\"Het opgegeven model kan niet gevonden worden. de code is onderbroken\")\n",
    "\n",
    "# Maakt een lijst van alle bestanden in de input mappen en hun sub mappen. slaan de File.stem op om te controleren of we labels bij afbeeldingen hebben \n",
    "# en slaan de File.parent op om alle mappen met bruikbare bestanden te kunnen gebruiken ipv alle folder iedere keer te scannen\n",
    "with OutputScreenLoadingBar:\n",
    "    for Paths in tqdm(InputAnnotaties, desc=\"1/4 Bestanden scannen\"):\n",
    "        for root, dirs, files in os.walk(Paths):\n",
    "            for File in files:\n",
    "                File = Path(os.path.join(root, File))\n",
    "                if File.suffix.lower() == \".txt\":\n",
    "                    AllTextInput.append(File.stem)\n",
    "                    RootFiles.add(File.parent)\n",
    "                elif File.suffix.lower() in [\".jpg\", \".png\", \"jpeg\"]:\n",
    "                    AllImageInput.append(File.stem)\n",
    "                    RootFiles.add(File.parent)\n",
    "\n",
    "if len(set(AllImageInput).intersection(AllTextInput)) == 0:\n",
    "    sys.exit(\"Er zijn geen Images met bijbehorende labels gevonden. de code is onderbroken\")\n",
    "\n",
    "# scan alle potentiële bestanden en behoud alleen de path's van labels met afbeeldingen en vice versa\n",
    "# Is een aparte loop van voorgaande om moeilijk doen met de volgorde van eerst label of afbeelding vinden te omzeilen\n",
    "with OutputScreenLoadingBar:\n",
    "    for Paths in tqdm(RootFiles, desc=\"2/4 Bestanden Selecteren\"):\n",
    "        Scan = PurePath(Paths)\n",
    "        for File in tqdm(os.listdir(Paths), f\"| - {Scan.parent.name}/{Scan.name}\", leave=True):\n",
    "            File = Path(os.path.join(Scan, File))\n",
    "                \n",
    "            if not os.path.isdir(File):\n",
    "                if File.stem in AllImageInput and File.stem in AllTextInput:\n",
    "                    PathsInput.append(File)\n",
    "\n",
    "                # Filtert alle \"labels.txt\" eruit en slaat één versie op. geeft een print statement als het 2 unieke bestanden vind met andere (volgorde van) labels.\n",
    "                # Dit kan later in het script voor problemen zorgen als de labels echt anders zijn.\n",
    "                elif File.name.lower() == \"labels.txt\":\n",
    "                    if not labels:\n",
    "                        labels = File\n",
    "                        with open(labels, \"r\") as Text:\n",
    "                            labelsText=Text.read()\n",
    "                    else:\n",
    "                        with open(File, \"r\") as Text:\n",
    "                            if Text.read() != labelsText:\n",
    "                                with OutputScreenPrintDisplay:\n",
    "                                    print(f\"de inhoud van labelbestanden op:\\n{labels}\\n\\nverschild met de inhoud van\\n{files}\\n\\nDe inhoud van het volgende bestand word aangehouden:\\n{labels}\\n\\n\")\n",
    "\n",
    "#*************************************************************************************************\n",
    "# Functie om te kunnen valideren dat een File.stem coördinaten bevat en dus een segment is\n",
    "def ContainsCords(FileStem : str):\n",
    "    NameSplit = FileStem.rsplit(ScheidingsTekenCoördinaten, 2)\n",
    "\n",
    "    try:\n",
    "        NameSplit[-3]\n",
    "        int(NameSplit[-2])\n",
    "        int(NameSplit[-1])\n",
    "        return True\n",
    "    except (ValueError, IndexError):\n",
    "        return False\n",
    "\n",
    "# Functie om te kunnen valideren dat een File.stem opgedeeld kan worden aan de hand ven het opgegeven scheidingsteken    \n",
    "def ContainsVariables(FileStem: str):\n",
    "    if ScheidingsTekenVariabelen:\n",
    "        NameSplit = FileStem.rsplit(ScheidingsTekenVariabelen)\n",
    "\n",
    "        # Wanneer het teken van variabelen en coördinaten gelijk is en een naam bevat coördinaten is het minimum delen 3 : naam _ ycor _ xcor \n",
    "        if ContainsCords(FileStem) and ScheidingsTekenVariabelen == ScheidingsTekenCoördinaten:\n",
    "            MinimumLength = 3\n",
    "        else:\n",
    "            MinimumLength = 1\n",
    "\n",
    "        if len(NameSplit) > MinimumLength:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "Clustering.sort()\n",
    "\n",
    "# Loop om bestanden te koieeren naar de nieuwe dataset/datapunt\n",
    "with OutputScreenLoadingBar:\n",
    "    for files in tqdm(PathsInput, desc=\"3/4 Bestanden herordenen\"):\n",
    "        File = Path(files)\n",
    "        FileStem = File.stem\n",
    "\n",
    "        # Bepaalt de dataset voor opslag. houd rekening mee of de gebruiker segmentatie of variabelen wil gebruiken voor groepering. \n",
    "        # Maar negeert instellingen wanneer geen coördinaten gevonden kan worden. Las er ook geen variabelen gevonden kan worden of geen scheiding teken is opgegeven word een bestand niet mee genomen\n",
    "        # Dit is om validatie op te kleine datasets te voorkomen\n",
    "        if ContainsCords(FileStem) and not GebruikVariabelClustering:\n",
    "            MainDir, _, _ = FileStem.rsplit(ScheidingsTekenCoördinaten, 2)\n",
    "        elif ContainsCords(FileStem) and ContainsVariables(FileStem):\n",
    "            Tijdelijk, _, _ = FileStem.rsplit(ScheidingsTekenCoördinaten, 2)\n",
    "            _, MainDir = Tijdelijk.split(ScheidingsTekenVariabelen, 1)\n",
    "        elif ContainsVariables(FileStem):\n",
    "            _, MainDir = FileStem.split(ScheidingsTekenVariabelen, 1)\n",
    "        else:\n",
    "            with OutputScreenPrintDisplay:\n",
    "                if GebruikVariabelClustering and ContainsCords(FileStem):\n",
    "                    print(f\"{File.name} mag niet op Segmenten geclusterd worden en bevat geen valide variabelen({ScheidingsTekenVariabelen}). \\n Om validatie op datasets met minder dan {MinimaalAantalBestanden} bestand te voorkomen word {File.name} niet veder meegenomen.\")\n",
    "                elif GebruikVariabelClustering:\n",
    "                    print(f\"{File.name} mag niet en kan niet op Segmenten geclusterd worden en bevat geen valide variabelen({ScheidingsTekenVariabelen}). \\n Om validatie op datasets met minder dan {MinimaalAantalBestanden} bestand te voorkomen word {File.name} niet veder meegenomen.\")\n",
    "                else:\n",
    "                    print(f\"{File.name} kan niet op Segmenten geclusterd worden en bevat geen valide variabelen({ScheidingsTekenVariabelen}). \\n Om validatie op datasets met minder dan {MinimaalAantalBestanden} bestand te voorkomen word {File.name} niet veder meegenomen.\")\n",
    "                continue\n",
    "\n",
    "        # filterd op bestandstype en slaat bestand dan op in nieuwe dataset/datapunt\n",
    "        if File.suffix.lower() == \".txt\":\n",
    "            IsLabel = True\n",
    "            FileCopy(Main = MainDir, \n",
    "                    IsLabel = IsLabel,\n",
    "                    FilePath = File\n",
    "                    )\n",
    "        elif File.suffix.lower() in [\".jpg\", \".png\", \"jpeg\"]:\n",
    "            IsLabel = False\n",
    "            FileCopy(Main = MainDir, \n",
    "                    IsLabel = IsLabel,\n",
    "                    FilePath = File\n",
    "                    )\n",
    "        \n",
    "        # Checkt of er clusters gemaakt moeten worden en zo ja of het huidige bestand ook aan deze dataset/dit datapunt toegevoegd moet worden\n",
    "        if Clustering and ScheidingsTekenVariabelen:\n",
    "            FileSplit = MainDir.split(ScheidingsTekenVariabelen) \n",
    "\n",
    "            # Sorteer opgegeven variabelen om de grootse te kunnen selecteren. \n",
    "            # gebruikt om te checken of huidige bestand genoeg variabelen heeft om mee geclusterd te worden\n",
    "            Clustering.sort()\n",
    "            if len(FileSplit) >= Clustering[-1]:\n",
    "                ClusterOpslagNaam = f\"{ClusterSignaal}\"\n",
    "\n",
    "                for Variabelen in Clustering:\n",
    "\n",
    "                    VariabeleText = FileSplit[Variabelen-1] # -1 omdat listitems genummerd worden vanaf 0 ipv 1\n",
    "\n",
    "                    # Clusterd en veranderd namen van variabelen zoals opgegeven in VariabelenMatch door gebruiker\n",
    "                    for Key in VariabelenMatch.keys():\n",
    "                        for String in VariabelenMatch[Key]:\n",
    "                            if String == VariabeleText:\n",
    "                                VariabeleText = Key                \n",
    "                    \n",
    "                    # Slaat de positie(int) van het variabel in de naam op in een dic. In de output excel worden variabelen opgesplitst in kolommen met als header: Variabele i \n",
    "                    # met i de positie in het variabel in de originele bestandsnaam/MainDir omdat niet alle variabelen mee genomen worden in iedere clustering moet deze data terug te vinden zijn.\n",
    "                    ClusterDictionary[VariabeleText] = Variabelen\n",
    "                    \n",
    "                    if ClusterOpslagNaam == ClusterSignaal: # True = eerste variabel die word toegevoegd\n",
    "                        ClusterOpslagNaam = ClusterOpslagNaam + VariabeleText\n",
    "                    else:\n",
    "                        ClusterOpslagNaam = ClusterOpslagNaam + EnSignaal + VariabeleText\n",
    "\n",
    "                FileCopy(\n",
    "                    Main = ClusterOpslagNaam,\n",
    "                    IsLabel=IsLabel,\n",
    "                    FilePath = File\n",
    "                )\n",
    "            else:\n",
    "                with OutputScreenPrintDisplay:\n",
    "                    print(f\"De hoogste waardes van Clustering (={Clustering[-1]}) zijn groter dan het aantal Variabelen in {MainDir} (={len(FileSplit)}). \\n Bestand {File.stem} word niet meegenomen in de clustering\")\n",
    "#*************************************************************************************************                    \n",
    "\n",
    "# Eerst alle submappen tellen\n",
    "total_dirs = sum(len(dirs) for _, dirs, _ in os.walk(OutputFolder))\n",
    "\n",
    "# Voegt de labels en configfile toe aan iedere dataset/ ieder datapunt\n",
    "with OutputScreenLoadingBar:\n",
    "    with tqdm(total=total_dirs, desc=\"4/4 Aanvullende bestanden toevoegen\") as pbar:\n",
    "        for root, dirs, files in os.walk(OutputFolder):\n",
    "            for dir in dirs:\n",
    "                if dir == \"labels\": # labels komt één keer per dataset/datapunt voor dus images word genegeerd om duplicaat bestanden te voorkomen\n",
    "                    shutil.copy2(labels, os.path.join(root, dir, \"validation\", \"Labels.txt\"))\n",
    "\n",
    "\n",
    "                    with open(labels, \"r\") as a:\n",
    "                        names = {i: label.strip() for i, label in enumerate(a.readlines())}\n",
    "\n",
    "                    #genereert de text die uiteindelijk in het config bestand moet komen\n",
    "                    yaml_dict = {\n",
    "                        \"path\": os.path.join(os.getcwd(), root),\n",
    "                        \"train\": \"images\\\\train\",\n",
    "                        \"val\": \"images\\\\validation\",\n",
    "                        \"names\": names\n",
    "                    }\n",
    "\n",
    "                    #Maakt het een leeg config bestand met de juiste naam aan.\n",
    "                    Root = Path(root)\n",
    "                    ConfigLocation = os.path.join(root, f\"{Root.name}_Config.yaml\")\n",
    "                    with open(ConfigLocation, \"w+\") as b:\n",
    "                        b.write(\"\")\n",
    "                    \n",
    "                    #Schrijft het daadwerkelijke config bestand. Maakt een uitzondering voor names omdat deze een aparte notatie moet hebben\n",
    "                    with open(ConfigLocation, \"a\") as c:\n",
    "                        for key, value in yaml_dict.items():\n",
    "                            if key != \"names\":\n",
    "                                c.write(f\"{key}: {value}\\n\")\n",
    "                            else:\n",
    "                                c.write(f\"\\nnames:\\n\")\n",
    "                                for k, v in names.items():\n",
    "                                    c.write(f\"  {k}: {v}\\n\")\n",
    "                    \n",
    "                pbar.update(1)  # De voortgang met 1 verhogen bij elke iteratie\n",
    "\n",
    "\n",
    "with OutputScreenPrintDisplay:\n",
    "    if DuplicaatDocumenten:\n",
    "        print(\"De volgende documenten hebben duplicaten in de input map staan en zijn maar eenmalig gekopieerd:\")\n",
    "        for Files in DuplicaatDocumenten:\n",
    "            Files = Path(Files)\n",
    "            print(f\"| - {Files.name}\")\n",
    "        print(\"---\" * 20)\n",
    "#******************************************************************************************************************\n",
    "# Laat benodigde lege variabelen in\n",
    "Model = YOLO(ModelLocatie, task='detect')\n",
    "TotaalPerDataPunt = pd.DataFrame()\n",
    "MatrixPerDataPunt = pd.DataFrame()\n",
    "TotaalPerCluster = pd.DataFrame()\n",
    "MatrixPerCluster = pd.DataFrame()\n",
    "ConfigCount = 0\n",
    "MinimaalAantalBBoxen = 10\n",
    "\n",
    "# Maakt een class aan om hardnekkige print statements van YOLO validatie af te vangen\n",
    "class SuppressOutput:\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        self._original_stderr = sys.stderr\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "        sys.stderr = open(os.devnull, 'w')\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        sys.stdout.close()\n",
    "        sys.stderr.close()\n",
    "        sys.stdout = self._original_stdout\n",
    "        sys.stderr = self._original_stderr\n",
    "\n",
    "# Bepaalt de lengte ven de laatbalk\n",
    "for root, dirs, files in os.walk(OutputFolder):\n",
    "    for File in files:\n",
    "        if File.endswith(\"_Config.yaml\"):\n",
    "            ConfigCount += 1\n",
    "\n",
    "\n",
    "\n",
    "# loopt over alle dataset/datapunten heen en valideert ze een voor een\n",
    "OutputScreenLoadingBar.clear_output(wait = True)\n",
    "with OutputScreenLoadingBar:\n",
    "    with tqdm(total=ConfigCount, desc=\"Datasets valideren\") as pbar:\n",
    "        for root, dirs, files in os.walk(OutputFolder):\n",
    "            for File in files:\n",
    "                if File.endswith(\"_Config.yaml\"):\n",
    "                    DataSet : str = File.removesuffix(\"_Config.yaml\")\n",
    "                    UsedLabels = set()\n",
    "                    BBoxCount = 0\n",
    "                    BestandCount = 0\n",
    "                                \n",
    "                    # Loopt over alle Labels in de dataset/datapunt om aantal labels per uniek label te bepalen.\n",
    "                    # Word gebruikt om alleen de labels die gebruikt zijn toe te voegen aan de output excel \n",
    "                    # Controleert ook of dataset genoeg datapunten bevat voor validatie\n",
    "                    for filename in os.listdir(os.path.join(root, \"labels\", \"validation\")):\n",
    "                        if filename.endswith('.txt') and filename != \"Labels.txt\":  # Assuming annotations are stored as text files\n",
    "                            BestandCount += 1\n",
    "                            with open(os.path.join(root, \"labels\", \"validation\", filename), 'r') as f:\n",
    "                                lines = f.readlines()\n",
    "                                for line in lines:\n",
    "                                    BBoxCount += 1\n",
    "                                    UsedLabels.add(line.split()[0])\n",
    "                    if BestandCount < MinimaalAantalBestanden:\n",
    "                        with OutputScreenPrintDisplay:\n",
    "                            print(f\"Het datapunt {DataSet} heeft maar {BestandCount} Afbeeldingen. Om validatie op datasets met minder dan {MinimaalAantalBestanden} bestand te voorkomen word {DataSet} niet veder meegenomen.\")\n",
    "                        pbar.update(1)\n",
    "                        continue\n",
    "                    elif BBoxCount < MinimaalAantalBBoxen:\n",
    "                        with OutputScreenPrintDisplay:\n",
    "                            print(f\"Het datapunt {DataSet} heeft maar {BBoxCount} Bounding Boxen. Om validatie op datasets met minder dan {MinimaalAantalBBoxen} Bounding Boxen te voorkomen word {DataSet} niet veder meegenomen.\")\n",
    "                        pbar.update(1)\n",
    "                        continue\n",
    "\n",
    "                    # valideert zonder printstatements\n",
    "                    with SuppressOutput():\n",
    "                        ValResult = Model.val(\n",
    "                            data=os.path.join(root, File), \n",
    "                            save_json=True, \n",
    "                            exist_ok=True, \n",
    "                            split=\"val\", \n",
    "                            project= root, \n",
    "                            name= \"MassValidatieOutput\", \n",
    "                            augment=True\n",
    "                        )\n",
    "\n",
    "                    Headers = []\n",
    "                    ValueOutput = True\n",
    "                    ValueCounter = 0\n",
    "                    while ValueOutput == True:\n",
    "                        Head = ValResult.names[ValueCounter]\n",
    "                        if Head:\n",
    "                            if str(ValueCounter) in UsedLabels:\n",
    "                                Headers.append(Head)\n",
    "                            Head = \"\"\n",
    "                            ValueCounter += 1\n",
    "                        if ValueCounter not in ValResult.names:\n",
    "                            ValueOutput = False\n",
    "\n",
    "                    # Verzamel alle resultaatdata van de validatie\n",
    "                    Headers = np.array(Headers)\n",
    "                    Precision = ValResult.box.p\n",
    "                    Recall = ValResult.box.r\n",
    "                    mAP50 = ValResult.box.ap50\n",
    "                    mAP95 = ValResult.box.ap\n",
    "                    F1Score = ValResult.box.f1\n",
    "\n",
    "                    # maakt output excel met de verzamelde data\n",
    "                    ExelOutput = pd.DataFrame([Headers, Precision, Recall, F1Score, mAP50, mAP95], index=[\"class\", \"Box Precision\", \"Box Recall\", \"Box F1-score\", \"mAP50\", \"mAP50-95\"])\n",
    "                    ExelOutput = ExelOutput.transpose()\n",
    "\n",
    "                    # Gebruikt het eerder gevonden Labels.txt om de headers van de nieuwe tabel te bepalen\n",
    "                    with open(labels, \"r\") as a:\n",
    "                        HeadersConfusionMatrix = [x.strip(\"\\n\") for x in a.readlines()]\n",
    "                    HeadersConfusionMatrix.append(\"Achtergrond\")\n",
    "\n",
    "                    # Haalt de data voor de confusion matrix uit de validatie resultaten en update de opmaak voor het output excel\n",
    "                    ConfusionMatrix = pd.DataFrame(\n",
    "                        ValResult.confusion_matrix.matrix,  \n",
    "                        index = map(lambda x: \"Model: \"+x, HeadersConfusionMatrix),\n",
    "                    )\n",
    "                    ConfusionMatrix = ConfusionMatrix.T\n",
    "\n",
    "                    RawData = pd.DataFrame(\n",
    "                        columns = [\n",
    "                            \"class\",\n",
    "                            \"Mens: Instances\", \n",
    "                            \"Model: Instances\", \n",
    "                            \"True Positives\", \n",
    "                            \"False Positives\", \n",
    "                            \"False Negatives\"\n",
    "                        ])\n",
    "                    RawData[\"class\"] = HeadersConfusionMatrix[0:(len(HeadersConfusionMatrix)-1)]\n",
    "                    \n",
    "                    # Bereken extra waardes op basis van het samenvatten van resultaten\n",
    "                    for i in range(0, (len(HeadersConfusionMatrix)-1)):\n",
    "                        RawData.loc[RawData.index[i], \"Mens: Instances\"] = ConfusionMatrix.iloc[i].sum()\n",
    "                        RawData.loc[RawData.index[i], \"Model: Instances\"] = ConfusionMatrix.iloc[:,i].sum()\n",
    "                        RawData.loc[RawData.index[i], \"True Positives\"] = ConfusionMatrix.iloc[i, i]\n",
    "                        RawData.loc[RawData.index[i], \"False Positives\"] = ConfusionMatrix.iloc[:,i].sum() - ConfusionMatrix.iloc[i, i]\n",
    "                        RawData.loc[RawData.index[i], \"False Negatives\"] = ConfusionMatrix.iloc[i].sum() - ConfusionMatrix.iloc[i, i]\n",
    "\n",
    "\n",
    "                    ConfusionMatrix.insert(0, \"\", list(map(lambda x: \"Mens: \"+x, HeadersConfusionMatrix)))\n",
    "\n",
    "                    ExelOutput = pd.merge(RawData, ExelOutput, on=\"class\", how = \"outer\")\n",
    "\n",
    "                    # Berekend een ongewogen gemiddelde van alle waardes en voegt deze toe aan de output excel\n",
    "                    MensInstances = ExelOutput[\"Mens: Instances\"].sum()\n",
    "                    ModelInstances = ExelOutput[\"Model: Instances\"].sum()\n",
    "                    TruePositives = ExelOutput[\"True Positives\"].sum()\n",
    "                    FalsePositives = ExelOutput[\"False Positives\"].sum()\n",
    "                    FalseNegatives = ExelOutput[\"False Negatives\"].sum()\n",
    "                    PrecisionMean = np.nanmean(Precision)\n",
    "                    RecallMean = np.nanmean(Recall)\n",
    "                    mAP50Mean = np.nanmean(mAP50)\n",
    "                    mAP95Mean = np.nanmean(mAP95)\n",
    "                    \n",
    "                    ExelOutput = ExelOutput.T\n",
    "                    ExelOutput[len(ExelOutput.columns)] = [\n",
    "                        \"Ongewogen gemiddelden\",  \n",
    "                        MensInstances,\n",
    "                        ModelInstances,\n",
    "                        TruePositives,\n",
    "                        FalsePositives,\n",
    "                        FalseNegatives, \n",
    "                        PrecisionMean, \n",
    "                        RecallMean, \n",
    "                        (2*((PrecisionMean * RecallMean)/(PrecisionMean + RecallMean))), # Formule van de F1 score\n",
    "                        mAP50Mean, \n",
    "                        mAP95Mean, \n",
    "                    ]\n",
    "                    ExelOutput = ExelOutput.T\n",
    "\n",
    "                    # Berekend P, R en F1 opnieuw volgens de formule ipv het gemiddelde van vele losse waardes te gebruiken\n",
    "                    ExelOutput.insert(\n",
    "                        6, \n",
    "                        \"ConfusionMatrix Precision\", \n",
    "                        (\n",
    "                            ExelOutput[\"True Positives\"]/\n",
    "                            (ExelOutput[\"True Positives\"] + ExelOutput[\"False Positives\"])\n",
    "                        ))\n",
    "\n",
    "                    ExelOutput.insert(\n",
    "                        7, \n",
    "                        \"ConfusionMatrix Recall\", \n",
    "                        (\n",
    "                            ExelOutput[\"True Positives\"]/\n",
    "                            (ExelOutput[\"True Positives\"] + ExelOutput[\"False Negatives\"])\n",
    "                        ))\n",
    "\n",
    "                    ExelOutput.insert(\n",
    "                        8, \n",
    "                        \"ConfusionMatrix F1-score\", \n",
    "                        (\n",
    "                            (2 * (ExelOutput[\"ConfusionMatrix Precision\"] * ExelOutput[\"ConfusionMatrix Recall\"]))/\n",
    "                            (ExelOutput[\"ConfusionMatrix Precision\"] + ExelOutput[\"ConfusionMatrix Recall\"])\n",
    "                            \n",
    "                        ))\n",
    "\n",
    "                    # Voegt kolom met de dataset naam toe\n",
    "                    ExelOutput.insert(0, \"SampleName\", DataSet)\n",
    "                    ConfusionMatrix.insert(0, \"SampleName\", DataSet)\n",
    "                    Variabele = 1\n",
    "                    \n",
    "                    # Voegt de individuele resultaten samen tot een groot excel voor opslag\n",
    "                    if DataSet.startswith(ClusterSignaal):\n",
    "                        Clustering.sort(reverse=True)\n",
    "\n",
    "                        # Voegt Dummy kolommen toe voor alle variabelen. variabelen in dit cluster worden later toegevoegd en overschrijven deze warde. \n",
    "                        # Zorcht ervoor dat waardes niet overschreven worden en dat Colomnummer voor specefieke variabelen gelijk zijn tussen clusters en losse data\n",
    "                        for values in Clustering:\n",
    "                            ExelOutput.insert(1, f\"Variabele {values}\", \"*\")\n",
    "                            ConfusionMatrix.insert(1, f\"Variabele {values}\", \"*\")\n",
    "\n",
    "                        DataSetVar = DataSet.removeprefix(ClusterSignaal).replace(EnSignaal, ScheidingsTekenVariabelen)\n",
    "\n",
    "                        # Vervangt Dummy waardes met echte variabelen waar nodig         \n",
    "                        for Var in DataSetVar.split(ScheidingsTekenVariabelen):\n",
    "                            ExelOutput[f\"Variabele {ClusterDictionary[Var]}\"] = Var\n",
    "                            ConfusionMatrix[f\"Variabele {ClusterDictionary[Var]}\"] = Var\n",
    "                            Variabele += 1\n",
    "\n",
    "                        # Voegt De output van dit cluster toe aan de totale output. Er word rekening gehouden met aantal kolommen omdat ander het overschot niet mee genomen word\n",
    "                        if len(TotaalPerCluster.columns) >= len(ExelOutput.columns):\n",
    "                            TotaalPerCluster = pd.concat([TotaalPerCluster, ExelOutput], ignore_index= True)\n",
    "                            MatrixPerCluster = pd.concat([MatrixPerCluster, ConfusionMatrix], ignore_index= True)\n",
    "                        else:\n",
    "                            TotaalPerCluster = pd.concat([ExelOutput, TotaalPerCluster], ignore_index= True)\n",
    "                            MatrixPerCluster = pd.concat([ConfusionMatrix, MatrixPerCluster], ignore_index= True)\n",
    "\n",
    "                        pbar.update(1)\n",
    "                    \n",
    "                    else:\n",
    "                        if ScheidingsTekenVariabelen:                        \n",
    "                            for Var in DataSet.split(ScheidingsTekenVariabelen):\n",
    "                                ExelOutput.insert(Variabele, f\"Variabele {Variabele}\", Var)\n",
    "                                ConfusionMatrix.insert(Variabele, f\"Variabele {Variabele}\", Var)\n",
    "                                Variabele += 1\n",
    "\n",
    "                        # Voegt De output van dit datapunt/dataset toe aan de totale output. Er word rekening gehouden met aantal kolommen omdat ander het overschot niet mee genomen word\n",
    "                        if len(TotaalPerDataPunt.columns) >= len(ExelOutput.columns):\n",
    "                            TotaalPerDataPunt = pd.concat([TotaalPerDataPunt, ExelOutput], ignore_index= True)\n",
    "                            MatrixPerDataPunt = pd.concat([MatrixPerDataPunt, ConfusionMatrix], ignore_index= True)\n",
    "                        else:\n",
    "                            TotaalPerDataPunt = pd.concat([ExelOutput, TotaalPerDataPunt], ignore_index= True)\n",
    "                            MatrixPerDataPunt = pd.concat([ConfusionMatrix, MatrixPerDataPunt], ignore_index= True)\n",
    "                            \n",
    "                        pbar.update(1)\n",
    "                    \n",
    "# Slaat alle resultaten op in de output Excel\n",
    "OutputFolder = Path(OutputFolder)\n",
    "if Clustering and ScheidingsTekenVariabelen:\n",
    "    with pd.ExcelWriter(os.path.join(OutputFolder, f\"AAA_Resultaten_{OutputFolder.stem}.xlsx\")) as Writer:\n",
    "        TotaalPerDataPunt.to_excel(Writer, sheet_name= \"Output per data punt\", index=False)\n",
    "        MatrixPerDataPunt.to_excel(Writer, sheet_name= \"Matrix per data punt\", index=False)\n",
    "        TotaalPerCluster.to_excel(Writer, sheet_name= \"Output per clusters\", index=False)\n",
    "        MatrixPerCluster.to_excel(Writer, sheet_name= \"Matrix per clusters\", index=False)\n",
    "else:\n",
    "    with pd.ExcelWriter(os.path.join(OutputFolder, f\"AAA_Resultaten_{OutputFolder.stem}.xlsx\")) as Writer:\n",
    "        TotaalPerDataPunt.to_excel(Writer, sheet_name= \"Output per data punt\", index=False)\n",
    "        MatrixPerDataPunt.to_excel(Writer, sheet_name= \"Matrix per data punt\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".UserVersion_VENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
